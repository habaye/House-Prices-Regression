{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors:Haben Abaye & Payal Singh\n",
    "# Course: CS697A\n",
    "# Date: 12/27/2020\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics\n",
    "from scipy.stats import norm,skew,probplot\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,StackingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(data,features): \n",
    "    all_outliers = defaultdict(list)\n",
    "    outlier_array = []\n",
    "    outlier_number = 5\n",
    "    for col in features:\n",
    "        lower_bound = np.percentile(data[col], 25)\n",
    "        upper_bound = np.percentile(data[col], 75)       \n",
    "        IQR = upper_bound - lower_bound \n",
    "        outlier_range = 1.7 * IQR        \n",
    "        outlier = data[(data[col] < lower_bound - outlier_range) | (data[col] > upper_bound + outlier_range )]\n",
    "        outlier_index = outlier.index        \n",
    "        outlier_array.extend(outlier_index)\n",
    "        \n",
    "    outlier_array = Counter(outlier_array) \n",
    "    for key,value in outlier_array.items():\n",
    "        if(value > outlier_number):\n",
    "            all_outliers[key].append(value)\n",
    "    return all_outliers\n",
    "    \n",
    "def clean_data(data):\n",
    "    threshold_value = 0.8\n",
    "    data = data[data.columns[data.isnull().mean() < threshold_value]]\n",
    "    return data\n",
    "\n",
    "def handle_missing_value(data):\n",
    "    for col in data.select_dtypes(include=['int64', 'float64']):\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "        \n",
    "    object_column = data.loc[:,'MSSubClass':'SaleCondition'].select_dtypes(include='object').columns\n",
    "    for col in object_column:\n",
    "        data[col] = data[col].fillna('NA')\n",
    "    return data\n",
    "\n",
    "def encode_data(data):\n",
    "    object_column = data.loc[:,'MSSubClass':'SaleCondition'].select_dtypes(include='object').columns\n",
    "    #handle ordinal data\n",
    "    ordinal = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond' ,'HeatingQC', 'KitchenQual', \n",
    "               'FireplaceQu','GarageQual', 'GarageCond','Utilities','BsmtFinType1','BsmtFinType2',\n",
    "               'GarageFinish']\n",
    "    label_mapping = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'NA':0,\n",
    "                     'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1,\n",
    "                    'Av':3, 'Mn':2, 'No':1, 'GLQ':6, 'ALQ':5, 'BLQ':4,\n",
    "                    'Rec':3, 'LwQ':2, 'Unf':1, 'Y':2, 'N':1, 'Fin':3,\n",
    "                    'RFn': 2, 'GdPrv':4, 'MnPrv':3, 'GdWo':2, 'MnWw':1}\n",
    "    for col in ordinal:\n",
    "        data[col] = data[col].map(label_mapping)\n",
    "        \n",
    "    #handle nominal data\n",
    "    nominal  = [item for item in object_column if item not in ordinal]\n",
    "    data = pd.get_dummies(data, columns=nominal, drop_first=True)\n",
    "    return data\n",
    "\n",
    "def add_features(data):\n",
    "    data['Total_area'] = data['LotArea']+data['1stFlrSF']+ data['2ndFlrSF']\n",
    "    data['Overall_type'] = data['OverallQual'] + data['OverallCond']\n",
    "    data['age']= abs(data['YrSold'] - data['YearBuilt'] )\n",
    "    data['remodeled'] = data['YearRemodAdd'] - data['YearBuilt']\n",
    "    return data\n",
    "\n",
    "\n",
    "def handle_skewness(data):\n",
    "    numerical_value= data.select_dtypes(exclude=object).columns\n",
    "    skew_value=data[numerical_value].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "    max_skew = 0.60\n",
    "    skew_value=skew_value[abs(skew_value)>max_skew]\n",
    "    skew_columns = skew_value.index\n",
    "    for col in skew_columns:\n",
    "        data[col] = boxcox1p(data[col], .22)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "url = \"train.csv\"\n",
    "train_csv = pd.read_csv(url)\n",
    "train = pd.DataFrame(train_csv)\n",
    "# Load Testing dataset\n",
    "url = \"test.csv\"\n",
    "test_csv = pd.read_csv(url)\n",
    "test = pd.DataFrame(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'] = np.log1p(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find outliers of training from numeric column \n",
    "numeric_data = train.loc[:,'MSSubClass':'SaleCondition'].select_dtypes(exclude=['object'])\n",
    "numeric_column = numeric_data.columns\n",
    "\n",
    "#get outliers\n",
    "outliers = get_outliers(train, numeric_column)\n",
    "#drop outliers\n",
    "train = train.drop(outliers, axis = 0).reset_index(drop=True)\n",
    "\n",
    "total_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'], test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "total_data = add_features(total_data)\n",
    "\n",
    "total_data = clean_data(total_data)\n",
    "total_data = handle_missing_value(total_data)\n",
    "total_data = encode_data(total_data)\n",
    "total_data = handle_skewness(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = total_data[:train.shape[0]]\n",
    "X_test_house = total_data[train.shape[0]:]\n",
    "label_data = train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, label_data, test_size=0.07,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True,criterion='mse',\n",
    "                           random_state=42,max_depth=45,\n",
    "                           max_features=30,\n",
    "                           n_estimators=1500,\n",
    "                           n_jobs=-1, verbose=2)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(booster='gbtree',\n",
    "                   colsample_bylevel=0.6, colsample_bynode=.4,#1,.5\n",
    "                   colsample_bytree=0.6, gamma=0,\n",
    "                   importance_type='gain', learning_rate=0.01,\n",
    "                   max_delta_step=0, max_depth=45,\n",
    "                   min_child_weight=4, n_estimators=2500,\n",
    "                   n_jobs=-1, nthread=None,\n",
    "                   objective='reg:linear', reg_alpha=0.6,\n",
    "                   reg_lambda=0.6, scale_pos_weight=1,\n",
    "                   silent=None, subsample=0.8,\n",
    "                   verbosity=2)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(max_depth=45, num_leaves=50,\n",
    "                    learning_rate=0.05, n_jobs=-1,\n",
    "                    boosting_type='gbdt', objective='regression',\n",
    "                    metric='rmse', verbosity=2,\n",
    "                    bagging_fraction=0.7, feature_fraction=0.6,\n",
    "                    bagging_freq=4, bagging_seed=42,\n",
    "                    seed=42, colsample_bynode=.6,\n",
    "                    colsample_bytree=.6)\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=4,leaf_size=60,\n",
    "                          p=1,metric='manhattan',weights='distance')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.01,\n",
    "                                max_depth=4, max_features='sqrt',\n",
    "                                min_samples_leaf=15, min_samples_split=5,\n",
    "                                loss='huber', random_state =42) \n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(criterion='mse',random_state=42,\n",
    "                            max_depth=5, max_features='sqrt',\n",
    "                            min_samples_leaf=15, min_samples_split=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr = AdaBoostRegressor(dtr,n_estimators=800,\n",
    "                        random_state=42,learning_rate=0.5)\n",
    "abr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostRegressor(depth=6,learning_rate=0.1,\n",
    "                        n_estimators=3500,eval_metric = 'RMSE')\n",
    "cat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPRegressor(hidden_layer_sizes=(84,84,84,84,84,84,84,84,84), n_iter_no_change=200,\n",
    "                  activation='relu', verbose=True,\n",
    "                  learning_rate_init=.0001, tol=0.000001,\n",
    "                  random_state=761, max_iter=30000,\n",
    "                  alpha=.0000001, solver='adam',\n",
    "                  learning_rate='adaptive')\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_model = rf.predict(X_test)\n",
    "print('RMSE RF: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = svr.predict(X_test)\n",
    "print('RMSE SVR: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = xgb.predict(X_test)\n",
    "print('RMSE XGB: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = abr.predict(X_test)\n",
    "print('RMSE ABR: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = lgb.predict(X_test)\n",
    "print('RMSE LGB: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = knn.predict(X_test)\n",
    "print('RMSE KNN: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = nn.predict(X_test)\n",
    "print('RMSE NN: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = cat.predict(X_test)\n",
    "print('RMSE CAT: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))\n",
    "\n",
    "y_pred_model = gbr.predict(X_test)\n",
    "print('RMSE GBR: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level0 = [('rf',rf),('xgb',xgb),('gbr',gbr),('lgb',lgb),\n",
    "          ('abr',abr),('cat',cat),('svr',svr),('nn',nn),\n",
    "         ('knn',knn)]\n",
    "level1 = xgb = XGBRegressor(booster='gbtree',\n",
    "                   colsample_bylevel=0.6, colsample_bynode=.4,#1,.5\n",
    "                   colsample_bytree=0.6, gamma=0,\n",
    "                   importance_type='gain', learning_rate=0.01,\n",
    "                   max_delta_step=0, max_depth=45,\n",
    "                   min_child_weight=4, n_estimators=2500,\n",
    "                   n_jobs=-1, nthread=None,\n",
    "                   objective='reg:linear', reg_alpha=0.6,\n",
    "                   reg_lambda=0.6, scale_pos_weight=1,\n",
    "                   silent=None, subsample=0.8,\n",
    "                   verbosity=2)\n",
    "#LinearRegression()\n",
    "stack = StackingRegressor(estimators=level0,final_estimator=level1,\n",
    "                          cv=5, verbose=2, n_jobs=-1)\n",
    "stack.fit(X_train, y_train)\n",
    "y_pred_stack= stack.predict(X_test)\n",
    "print('RMSE: %2f'% np.sqrt(mean_squared_error(y_test, y_pred_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_test_data = stack.predict(X_test_house)\n",
    "predict_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_result = pd.DataFrame()\n",
    "test = pd.DataFrame(test_csv)\n",
    "sub_result['Id'] = test['Id']\n",
    "sub_result['SalePrice'] = np.expm1(predict_test_data)\n",
    "sub_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_result.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
